{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimesFM with Covariates\n",
    "\n",
    "This toturial notebook demonstrates how to utilize exogenous covariates with TimesFM when making forecasts. Before running this notebook, make sure:\n",
    "\n",
    "- You've read through the README of TimesFM.\n",
    "- A local kernel with Python 3.10 is up and running, for the jax version.\n",
    "- Install the JAX version following the installation instructions.\n",
    "\n",
    "> Update:\n",
    ">\n",
    "> Save the raw and predict data by a dataframe, then export as file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment and install TimesFM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the checkpoint\n",
    "\n",
    "**Notice:** Please set up the backend as per your machine (\"cpu\", \"gpu\" or \"tpu\"). This notebook will run by default on GPU.\n",
    "\n",
    "We load the 2.0-500m model checkpoint from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timesfm\n",
    "timesfm_backend = \"gpu\"  # @param\n",
    "\n",
    "model = timesfm.TimesFm(\n",
    "      hparams=timesfm.TimesFmHparams(\n",
    "          backend=timesfm_backend,\n",
    "          per_core_batch_size=32,\n",
    "          horizon_len=128,\n",
    "          num_layers=50,\n",
    "          use_positional_embedding=False,\n",
    "          context_len=2048,\n",
    "      ),\n",
    "      checkpoint=timesfm.TimesFmCheckpoint(\n",
    "          huggingface_repo_id=\"google/timesfm-2.0-500m-pytorch\"),\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariates\n",
    "\n",
    "Let's take a toy example of forecasting sales for a grocery store: \n",
    "\n",
    "**Task:** Given the observed the daily sales of this week (7 days), forecast the daily sales of next week (7 days).\n",
    "\n",
    "```\n",
    "Product: ice cream\n",
    "Daily_sales: [30, 30, 4, 5, 7, 8, 10]\n",
    "Category: food\n",
    "Base_price: 1.99\n",
    "Weekday: [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6]\n",
    "Has_promotion: [Yes, Yes, No, No, No, Yes, Yes, No, No, No, No, No, No, No]\n",
    "Daily_temperature: [31.0, 24.3, 19.4, 26.2, 24.6, 30.0, 31.1, 32.4, 30.9, 26.0, 25.0, 27.8, 29.5, 31.2]\n",
    "```\n",
    "\n",
    "```\n",
    "Product: sunscreen\n",
    "Daily_sales: [5, 7, 12, 13, 5, 6, 10]\n",
    "Category: skin product\n",
    "Base_price: 29.99\n",
    "Weekday: [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6]\n",
    "Has_promotion: [No, No, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes]\n",
    "Daily_temperature: [31.0, 24.3, 19.4, 26.2, 24.6, 30.0, 31.1, 32.4, 30.9, 26.0, 25.0, 27.8, 29.5, 31.2]\n",
    "```\n",
    "\n",
    "In this example, besides the `Daily_sales`, we also have covariates `Category`, `Base_price`, `Weekday`, `Has_promotion`, `Daily_temperature`. Let's introduce some concepts:\n",
    "\n",
    "**Static covariates** are covariates for each time series. \n",
    "- In our example, `Category` is a **static categorical covariate**, \n",
    "- `Base_price` is a **static numerical covariates**.\n",
    "\n",
    "**Dynamic covariates** are covaraites for each time stamps.\n",
    "- Date / time related features can be usually treated as dynamic covariates.\n",
    "- In our example, `Weekday` and `Has_promotion` are **dynamic categorical covariates**.\n",
    "- `Daily_temperate` is a **dynamic numerical covariate**.\n",
    "\n",
    "**Notice:** Here we make it mandatory that the dynamic covariates need to cover both the forecasting context and horizon. For example, all dynamic covariates in the example have 14 values: the first 7 correspond to the observed 7 days, and the last 7 correspond to the next 7 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimesFM with Covariates\n",
    "\n",
    "\n",
    "The strategy we take here is to treat covariates as batched in-context exogenous regressors (XReg) and fit linear models on them outside of TimesFM. The final forecast will be the sum of the TimesFM forecast and the linear model forecast.\n",
    "\n",
    " In simple words, we consider these two options.\n",
    "\n",
    "**Option 1:** Get the TimesFM forecast, and fit the linear model regressing the residuals on the covariates (\"timesfm + xreg\").\n",
    "\n",
    "**Option 2:** Fit the linear model of the time series itself on the covariates, then forecast the residuals using TimesFM  (\"xreg + timesfm\").\n",
    "\n",
    "Let's take a code at the example of Electricity Price Forecasting (EPF). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>county</th>\n",
       "      <th>onset_date</th>\n",
       "      <th>value</th>\n",
       "      <th>last_n_days</th>\n",
       "      <th>last_n_days_neighbor</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>发热伴</td>\n",
       "      <td>东平县</td>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>发热伴</td>\n",
       "      <td>东平县</td>\n",
       "      <td>2013-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>发热伴</td>\n",
       "      <td>东平县</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>发热伴</td>\n",
       "      <td>东平县</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>发热伴</td>\n",
       "      <td>东平县</td>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667575</th>\n",
       "      <td>肾综合</td>\n",
       "      <td>龙口市</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667576</th>\n",
       "      <td>肾综合</td>\n",
       "      <td>龙口市</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667577</th>\n",
       "      <td>肾综合</td>\n",
       "      <td>龙口市</td>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608152</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667578</th>\n",
       "      <td>肾综合</td>\n",
       "      <td>龙口市</td>\n",
       "      <td>2024-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667579</th>\n",
       "      <td>肾综合</td>\n",
       "      <td>龙口市</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3667580 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        disease county onset_date  value  last_n_days  last_n_days_neighbor  \\\n",
       "0           发热伴    东平县 2013-04-22      0            0              0.000000   \n",
       "1           发热伴    东平县 2013-04-23      0            0              0.000000   \n",
       "2           发热伴    东平县 2013-04-24      0            0              0.000000   \n",
       "3           发热伴    东平县 2013-04-25      0            0              0.000000   \n",
       "4           发热伴    东平县 2013-04-26      0            0              0.000000   \n",
       "...         ...    ...        ...    ...          ...                   ...   \n",
       "3667575     肾综合    龙口市 2024-12-04      0            0              0.000000   \n",
       "3667576     肾综合    龙口市 2024-12-05      0            0              0.000000   \n",
       "3667577     肾综合    龙口市 2024-12-06      0            0              0.608152   \n",
       "3667578     肾综合    龙口市 2024-12-07      0            0              0.000000   \n",
       "3667579     肾综合    龙口市 2024-12-08      0            0              0.000000   \n",
       "\n",
       "         weekday  month  year  \n",
       "0              0      4  2013  \n",
       "1              1      4  2013  \n",
       "2              2      4  2013  \n",
       "3              3      4  2013  \n",
       "4              4      4  2013  \n",
       "...          ...    ...   ...  \n",
       "3667575        2     12  2024  \n",
       "3667576        3     12  2024  \n",
       "3667577        4     12  2024  \n",
       "3667578        5     12  2024  \n",
       "3667579        6     12  2024  \n",
       "\n",
       "[3667580 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE.csv')\n",
    "df = pd.read_csv('raw_day_data.csv')\n",
    "df['onset_date'] = pd.to_datetime(df['onset_date'],format='%Y-%m-%d')\n",
    "df['weekday'] = df['onset_date'].dt.weekday\n",
    "df['month'] = df['onset_date'].dt.month\n",
    "df['year'] = df['onset_date'].dt.year\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = df['county'].unique()\n",
    "diseases = df['disease'].unique()\n",
    "df_counties = pd.read_csv('df_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipelining\n",
    "def get_batched_data_fn(\n",
    "    disease: str,\n",
    "    county: str,\n",
    "    batch_size: int = 128, \n",
    "    context_len: int = 364, \n",
    "    horizon_len: int = 7,\n",
    "):\n",
    "  examples = defaultdict(list)\n",
    "  if county is not None:\n",
    "    counties_ = [county]\n",
    "  else:\n",
    "    counties_ = counties.copy()\n",
    "  num_examples = 0\n",
    "  for county in counties_:\n",
    "    sub_df = df[(df[\"disease\"] == disease) & (df[\"county\"] == county)]\n",
    "    \n",
    "    for start in range(0, len(sub_df) - (context_len + horizon_len), horizon_len):\n",
    "      num_examples += 1\n",
    "      examples[\"disease\"].append(disease)\n",
    "      examples[\"county\"].append(county)\n",
    "      examples['long'].append(df_counties[df_counties['county'] == county]['long'].values[0])\n",
    "      examples['lat'].append(df_counties[df_counties['county'] == county]['lat'].values[0])\n",
    "      examples[\"inputs\"].append(sub_df[\"value\"][start:(context_end := start + context_len)].tolist())\n",
    "      examples[\"last_n_days\"].append(sub_df[\"last_n_days\"][start:context_end + horizon_len].tolist())\n",
    "      examples[\"last_n_days_neighbor\"].append(sub_df[\"last_n_days_neighbor\"][start:context_end + horizon_len].tolist())\n",
    "      examples['onset_date'].append(sub_df['onset_date'][start:context_end + horizon_len].tolist())\n",
    "      examples['weekday'].append(sub_df['weekday'][start:context_end + horizon_len].tolist())\n",
    "      examples['month'].append(sub_df['month'][start:context_end + horizon_len].tolist())\n",
    "      examples['year'].append(sub_df['year'][start:context_end + horizon_len].tolist())\n",
    "      examples[\"outputs\"].append(sub_df[\"value\"][context_end:(context_end + horizon_len)].tolist())\n",
    "  \n",
    "  def data_fn():\n",
    "    for i in range(1 + (num_examples - 1) // batch_size):\n",
    "      yield {k: v[(i * batch_size) : ((i + 1) * batch_size)] for k, v in examples.items()}\n",
    "  \n",
    "  return data_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def mse(y_pred, y_true):\n",
    "  y_pred = np.array(y_pred)\n",
    "  y_true = np.array(y_true)\n",
    "  return np.mean(np.square(y_pred - y_true), axis=1, keepdims=True)\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "  y_pred = np.array(y_pred)\n",
    "  y_true = np.array(y_true)\n",
    "  return np.mean(np.abs(y_pred - y_true), axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try `model.forecast_with_covariates`. \n",
    "\n",
    "In particular, the output is a tuple whose first element is the new forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Benchmark\n",
    "batch_size = 128\n",
    "context_len = 364\n",
    "horizon_len = 7\n",
    "\n",
    "df_data = defaultdict(list)\n",
    "metrics_mean = defaultdict(list)\n",
    "for disease in tqdm(diseases):\n",
    "  input_data = get_batched_data_fn(disease, None, batch_size, context_len, horizon_len)\n",
    "  metrics = defaultdict(list)\n",
    "\n",
    "  for i, example in enumerate(input_data()):\n",
    "\n",
    "    raw_forecast, _ = model.forecast(\n",
    "        inputs=example[\"inputs\"], freq=[0] * len(example[\"inputs\"])\n",
    "    )\n",
    "    raw_forecast = np.array(raw_forecast).astype(np.int16)\n",
    "    raw_forecast[raw_forecast < 0] = 0\n",
    "    start_time = time.time()\n",
    "    # Forecast with covariates\n",
    "    # Output: new forecast, forecast by the xreg\n",
    "    cov_forecast, ols_forecast = model.forecast_with_covariates(  \n",
    "        inputs=example[\"inputs\"],\n",
    "        dynamic_numerical_covariates={\n",
    "            'last_n_days': example['last_n_days'],\n",
    "            'last_n_days_neighbor': example['last_n_days_neighbor'],\n",
    "            # 'onset_date': example['onset_date']\n",
    "        },\n",
    "        dynamic_categorical_covariates={\n",
    "            'weekday': example['weekday'],\n",
    "            'month': example['month'],\n",
    "            'year': example['year']\n",
    "        },\n",
    "        static_numerical_covariates={\n",
    "          'long': example['long'],\n",
    "          'lat': example['lat']\n",
    "        },\n",
    "        static_categorical_covariates={\n",
    "          \"disease\": example['disease'],\n",
    "          \"county\": example[\"county\"]\n",
    "        },\n",
    "        freq=[0] * len(example[\"inputs\"]),\n",
    "        xreg_mode=\"xreg + timesfm\",              # default\n",
    "        ridge=0.0,\n",
    "        force_on_cpu=False,\n",
    "        normalize_xreg_target_per_input=True,    # default\n",
    "    )\n",
    "    print(\n",
    "        f\"\\rFinished batch {i} linear in {time.time() - start_time} seconds\",\n",
    "        end=\"\",\n",
    "    )\n",
    "\n",
    "    cov_forecast = np.array(cov_forecast).astype(np.int16)\n",
    "    ols_forecast = np.array(ols_forecast).astype(np.int16)\n",
    "    cov_forecast[cov_forecast < 0] = 0\n",
    "    ols_forecast[ols_forecast < 0] = 0\n",
    "    cov_forecast = cov_forecast.tolist()\n",
    "    ols_forecast = ols_forecast.tolist()\n",
    "\n",
    "    df_data[\"disease\"].extend(np.reshape([example[\"disease\"]]*horizon_len, shape=-1, order='F'))\n",
    "    df_data[\"county\"].extend(np.reshape([example[\"county\"]]*horizon_len, shape=-1, order='F'))\n",
    "    df_data[\"onset_date\"].extend([item for sublist in example[\"onset_date\"] for item in sublist[-horizon_len:]])\n",
    "    df_data[\"number_of_cases\"].extend(np.reshape(example[\"outputs\"], shape=-1, order='C'))\n",
    "    df_data[\"raw_timesfm\"].extend(np.reshape(raw_forecast[:,:horizon_len], shape=-1, order='C'))\n",
    "    df_data[\"cov_timesfm\"].extend(np.reshape(cov_forecast, shape=-1, order='C'))\n",
    "    df_data[\"ols_timesfm\"].extend(np.reshape(ols_forecast, shape=-1, order='C'))\n",
    "    # for v in example[\"inputs\"]:\n",
    "    #     arima_model = ARIMA(v, order=(1, 0, 0))\n",
    "    #     arima_model_fit = arima_model.fit()\n",
    "    #     arima_forecast = arima_model_fit.forecast(horizon_len)\n",
    "    #     arima_forecast = arima_forecast.astype(np.int16)\n",
    "    #     arima_forecast[arima_forecast < 0] = 0\n",
    "    #     df_data[\"arima_forecast\"].extend(arima_forecast)\n",
    "\n",
    "    metrics[\"eval_mae_timesfm\"].extend(\n",
    "        mae(raw_forecast[:, :horizon_len], example[\"outputs\"])\n",
    "    )\n",
    "    metrics[\"eval_mae_xreg_timesfm\"].extend(mae(cov_forecast, example[\"outputs\"]))\n",
    "    metrics[\"eval_mae_xreg\"].extend(mae(ols_forecast, example[\"outputs\"]))\n",
    "    metrics[\"eval_mse_timesfm\"].extend(\n",
    "        mse(raw_forecast[:, :horizon_len], example[\"outputs\"])\n",
    "    )\n",
    "    metrics[\"eval_mse_xreg_timesfm\"].extend(mse(cov_forecast, example[\"outputs\"]))\n",
    "    metrics[\"eval_mse_xreg\"].extend(mse(ols_forecast, example[\"outputs\"]))\n",
    "\n",
    "  metrics_mean['disease'].append(disease)\n",
    "  for k, v in metrics.items():\n",
    "    print(f\"{k}: {np.mean(v)}\")\n",
    "    metrics_mean[k].append(np.mean(v))\n",
    "\n",
    "pd.DataFrame(data=metrics_mean).to_csv('metrics_mean.csv')\n",
    "pd.DataFrame(data=df_data).to_csv('df_data_raw_timesfm.csv')\n",
    "\n",
    "# My output:\n",
    "# Finished batch 875 linear in 0.27478981018066406 seconds\n",
    "# eval_mae_timesfm: 0.07512708441369645\n",
    "# eval_mae_xreg_timesfm: 0.07916631111473996\n",
    "# eval_mae_xreg: 0.14125861948193896\n",
    "# eval_mse_timesfm: 0.16500590590719252\n",
    "# eval_mse_xreg_timesfm: 0.12941367672275625\n",
    "# eval_mse_xreg: 0.24756478278784388"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The follow cell predict by ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac62d20a86f64e11b921ac4e83b2ce02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59367/554365869.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmetrics_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdisease\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiseases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_data_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisease\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_59367/986188352.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(disease, county, batch_size, context_len, horizon_len)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcontext_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhorizon_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mnum_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"disease\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisease\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"county\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_counties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_counties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'county'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcounty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_counties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_counties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'county'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcounty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_end\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last_n_days\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last_n_days\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcontext_end\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhorizon_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/timesfm[torch]/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4074\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4075\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4076\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m             ):\n\u001b[0;32m-> 4078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4081\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/timesfm[torch]/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4635\u001b[0m             \u001b[0;31m# All places that call _get_item_cache have unique columns,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4636\u001b[0m             \u001b[0;31m#  pending resolution of GH#33047\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4638\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4639\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4641\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/timesfm[torch]/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3984\u001b[0m         \"\"\"\n\u001b[1;32m   3985\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3986\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Benchmark\n",
    "batch_size = 128\n",
    "context_len = 364\n",
    "horizon_len = 7\n",
    "\n",
    "df_data = defaultdict(list)\n",
    "metrics_mean = defaultdict(list)\n",
    "for disease in tqdm(diseases):\n",
    "  input_data = get_batched_data_fn(disease, None, batch_size, context_len, horizon_len)\n",
    "  metrics = defaultdict(list)\n",
    "\n",
    "  for i, example in enumerate(input_data()):\n",
    "\n",
    "    # raw_forecast, _ = model.forecast(\n",
    "    #     inputs=example[\"inputs\"], freq=[0] * len(example[\"inputs\"])\n",
    "    # )\n",
    "    # raw_forecast = np.array(raw_forecast).astype(np.int16)\n",
    "    # raw_forecast[raw_forecast < 0] = 0\n",
    "    # start_time = time.time()\n",
    "    # Forecast with covariates\n",
    "    # Output: new forecast, forecast by the xreg\n",
    "    # cov_forecast, ols_forecast = model.forecast_with_covariates(  \n",
    "    #     inputs=example[\"inputs\"],\n",
    "    #     dynamic_numerical_covariates={\n",
    "    #         'last_n_days': example['last_n_days'],\n",
    "    #         'last_n_days_neighbor': example['last_n_days_neighbor'],\n",
    "    #         # 'onset_date': example['onset_date']\n",
    "    #     },\n",
    "    #     dynamic_categorical_covariates={\n",
    "    #         'weekday': example['weekday'],\n",
    "    #         'month': example['month'],\n",
    "    #         'year': example['year']\n",
    "    #     },\n",
    "    #     static_numerical_covariates={\n",
    "    #       'long': example['long'],\n",
    "    #       'lat': example['lat']\n",
    "    #     },\n",
    "    #     static_categorical_covariates={\n",
    "    #       \"disease\": example['disease'],\n",
    "    #       \"county\": example[\"county\"]\n",
    "    #     },\n",
    "    #     freq=[0] * len(example[\"inputs\"]),\n",
    "    #     xreg_mode=\"xreg + timesfm\",              # default\n",
    "    #     ridge=0.0,\n",
    "    #     force_on_cpu=False,\n",
    "    #     normalize_xreg_target_per_input=True,    # default\n",
    "    # )\n",
    "    # print(\n",
    "    #     f\"\\rFinished batch {i} linear in {time.time() - start_time} seconds\",\n",
    "    #     end=\"\",\n",
    "    # )\n",
    "\n",
    "    # cov_forecast = np.array(cov_forecast).astype(np.int16)\n",
    "    # ols_forecast = np.array(ols_forecast).astype(np.int16)\n",
    "    # cov_forecast[cov_forecast < 0] = 0\n",
    "    # ols_forecast[ols_forecast < 0] = 0\n",
    "    # cov_forecast = cov_forecast.tolist()\n",
    "    # ols_forecast = ols_forecast.tolist()\n",
    "\n",
    "    df_data[\"disease\"].extend(np.reshape([example[\"disease\"]]*horizon_len, shape=-1, order='F'))\n",
    "    df_data[\"county\"].extend(np.reshape([example[\"county\"]]*horizon_len, shape=-1, order='F'))\n",
    "    df_data[\"onset_date\"].extend([item for sublist in example[\"onset_date\"] for item in sublist[-horizon_len:]])\n",
    "    # df_data[\"number_of_cases\"].extend(np.reshape(example[\"outputs\"], shape=-1, order='C'))\n",
    "    # df_data[\"raw_timesfm\"].extend(np.reshape(raw_forecast[:,:horizon_len], shape=-1, order='C'))\n",
    "    # df_data[\"cov_timesfm\"].extend(np.reshape(cov_forecast, shape=-1, order='C'))\n",
    "    # df_data[\"ols_timesfm\"].extend(np.reshape(ols_forecast, shape=-1, order='C'))\n",
    "    arima_forecasts = []\n",
    "    for k,v in enumerate(example[\"inputs\"]):\n",
    "      arima_model = ARIMA(v, order=(1, 0, 0))\n",
    "      arima_model_fit = arima_model.fit()\n",
    "      arima_forecast = arima_model_fit.forecast(horizon_len)\n",
    "      arima_forecast = arima_forecast.astype(np.int16)\n",
    "      arima_forecast[arima_forecast < 0] = 0\n",
    "      df_data[\"number_of_cases\"].extend(example[\"outputs\"][k])\n",
    "      df_data[\"arima_forecast\"].extend(arima_forecast)\n",
    "      arima_forecasts.append(arima_forecast)\n",
    "\n",
    "    metrics[\"eval_mae_arima\"].extend(mae(arima_forecasts, example[\"outputs\"]))\n",
    "    metrics[\"eval_mse_arima\"].extend(mse(arima_forecasts, example[\"outputs\"]))\n",
    "\n",
    "    # metrics[\"eval_mae_timesfm\"].extend(\n",
    "    #     mae(raw_forecast[:, :horizon_len], example[\"outputs\"])\n",
    "    # )\n",
    "    # metrics[\"eval_mae_xreg_timesfm\"].extend(mae(cov_forecast, example[\"outputs\"]))\n",
    "    # metrics[\"eval_mae_xreg\"].extend(mae(ols_forecast, example[\"outputs\"]))\n",
    "    # metrics[\"eval_mse_timesfm\"].extend(\n",
    "    #     mse(raw_forecast[:, :horizon_len], example[\"outputs\"])\n",
    "    # )\n",
    "    # metrics[\"eval_mse_xreg_timesfm\"].extend(mse(cov_forecast, example[\"outputs\"]))\n",
    "    # metrics[\"eval_mse_xreg\"].extend(mse(ols_forecast, example[\"outputs\"]))\n",
    "\n",
    "  metrics_mean['disease'].append(disease)\n",
    "  for k, v in metrics.items():\n",
    "    print(f\"{k}: {np.mean(v)}\")\n",
    "    metrics_mean[k].append(np.mean(v))\n",
    "\n",
    "pd.DataFrame(data=metrics_mean).to_csv('metrics_mean_arima.csv', index=False)\n",
    "pd.DataFrame(data=df_data).to_csv('df_data_raw_ARIMA.csv',index=False)\n",
    "\n",
    "# My output:\n",
    "# Finished batch 875 linear in 0.27478981018066406 seconds\n",
    "# eval_mae_timesfm: 0.07512708441369645\n",
    "# eval_mae_xreg_timesfm: 0.07916631111473996\n",
    "# eval_mae_xreg: 0.14125861948193896\n",
    "# eval_mse_timesfm: 0.16500590590719252\n",
    "# eval_mse_xreg_timesfm: 0.12941367672275625\n",
    "# eval_mse_xreg: 0.24756478278784388"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1\n",
    "Dataset:\n",
    "inputs=example[\"inputs\"],\n",
    "dynamic_numerical_covariates={\n",
    "    \"last_7_days\": example[\"last_7_days\"],\n",
    "    \"last_7_days_neighbor\": example[\"last_7_days_neighbor\"],\n",
    "},\n",
    "dynamic_categorical_covariates={},\n",
    "static_numerical_covariates={},\n",
    "static_categorical_covariates={\n",
    "    \"disease\": example['disease'],\n",
    "    \"county\": example[\"county\"]\n",
    "},\n",
    "\n",
    "Parameters:\n",
    "batch_size = 128\n",
    "context_len = 365\n",
    "horizon_len = 7\n",
    "\n",
    "Output:\n",
    "eval_mae_timesfm: 0.06956844832217095\n",
    "eval_mae_xreg_timesfm: 0.07718363275138859\n",
    "eval_mae_xreg: 0.1458303443643856\n",
    "eval_mse_timesfm: 0.1238202625763847\n",
    "eval_mse_xreg_timesfm: 0.11236914567374198\n",
    "eval_mse_xreg: 0.2572237269098843\n",
    "\n",
    "\n",
    "## Test 2\n",
    "Dataset:\n",
    "inputs=example[\"inputs\"],\n",
    "dynamic_numerical_covariates={\n",
    "    \"last_7_days\": example[\"last_7_days\"],\n",
    "    \"last_7_days_neighbor\": example[\"last_7_days_neighbor\"],\n",
    "},\n",
    "dynamic_categorical_covariates={},\n",
    "static_numerical_covariates={\n",
    "    'long': example['long'],\n",
    "    'lat': example['lat']\n",
    "},\n",
    "static_categorical_covariates={\n",
    "    \"disease\": example['disease'],\n",
    "    \"county\": example[\"county\"]\n",
    "},\n",
    "\n",
    "Parameters:\n",
    "batch_size = 128\n",
    "context_len = 365\n",
    "horizon_len = 7\n",
    "\n",
    "Output:\n",
    "eval_mae_timesfm: 0.06956844832217095\n",
    "eval_mae_xreg_timesfm: 0.07717677639131347\n",
    "eval_mae_xreg: 0.14582863765527584\n",
    "eval_mse_timesfm: 0.1238202625763847\n",
    "eval_mse_xreg_timesfm: 0.11228735641782281\n",
    "eval_mse_xreg: 0.25722949054472055\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see results close to \n",
    "```\n",
    "eval_mae_timesfm: 6.729583250571446\n",
    "eval_mae_xreg_timesfm: 5.3375301110158\n",
    "eval_mae_xreg: 37.152760709266\n",
    "eval_mse_timesfm: 162.3132151851567\n",
    "eval_mse_xreg_timesfm: 120.9900627409689\n",
    "eval_mse_xreg: 1672.208769045399\n",
    "```\n",
    "\n",
    "With the covariates, the TimesFM forecast Mean Absolute Error improves from 6.73 to 5.34, and Mean Squred Error from 162.31 to 120.99. The results of purely fitting the linear model are also provided for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Your Request\n",
    "\n",
    "It is quite crucial to get the covariates properly formatted so that we can call this `model.forecast_with_covariates`. Please see its docstring for details. Here let's also grab a batch from a toy data input pipeline for quick explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_input_pipeline = get_batched_data_fn(batch_size=2, context_len=5, horizon_len=2)\n",
    "print(next(toy_input_pipeline()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something similar to this\n",
    "```\n",
    "{\n",
    "    'country': ['FR', 'FR'], \n",
    "    'inputs': [[53.48, 51.93, 48.76, 42.27, 38.41], [48.76, 42.27, 38.41, 35.72, 32.66]], \n",
    "    'gen_forecast': [[76905.0, 75492.0, 74394.0, 72639.0, 69347.0, 67960.0, 67564.0], [74394.0, 72639.0, 69347.0, 67960.0, 67564.0, 67277.0, 67019.0]], \n",
    "    'week_day': [[3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3]], \n",
    "    'outputs': [[35.72, 32.66], [32.83, 30.06]],\n",
    "}\n",
    "```\n",
    "\n",
    "Notice:\n",
    "- We have two examples in this batch.\n",
    "- For each example we support different context lengths and horizon lengths just as `model.forecast`. Although it is not demonstrated in this dataset.\n",
    "- If dynamic covariates are present, the horizon lengths will be inferred from them, e.g. how many values are provided in additional to the ones corresponding to the inputs. Make sure all your dynamic covariates have the same length per example.\n",
    "- The static covariates are one per example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Applications\n",
    "\n",
    "### Past Dynamic Covariates\n",
    "\n",
    "Past dynamic covariates are covariates that are only available for the context. For instance in our example `system_load` is a past dynamic covariate. Time series models generally can handle this, however it is something the batched in context regression cannot address, because these regressors are not available in the future. If you do have those covariates and consider them very meaningful, there are two hacky options to try immediately:\n",
    "\n",
    "1. Shift and repeat these past dynamic covariates to use their delayed version. For example, if you think the `system_load` for this week is meaningful for forecasting next week, you can create a `delay_7_system_load` by shifting 7 timestamps and use this as one dynamic numerical covariate for TimesFM.\n",
    "2. Bootstrap, that is to run TimesFM once to forecast these past dynamic covariates into the horizon, then call TimesFM again using these forecasts as the future part for these dynamic covariates.\n",
    "\n",
    "### Multivariate Time Series\n",
    "\n",
    "For multivariate time series, if we need univariate forecast, we can try treating the main time series as the target and use the rest as the dynamic covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "batch_size = 128\n",
    "context_len = 365\n",
    "horizon_len = 7\n",
    "disease = '手足口'\n",
    "county = '历城区'\n",
    "input_data = get_batched_data_fn(disease, county , batch_size, context_len, horizon_len)\n",
    "y_pred_timesfm = []\n",
    "y_pred_xreg_timesfm = []\n",
    "y_pred_xreg = []\n",
    "y_true = []\n",
    "\n",
    "for i, example in enumerate(input_data()):\n",
    "  raw_forecast, _ = model.forecast(\n",
    "      inputs=example[\"inputs\"], freq=[0] * len(example[\"inputs\"])\n",
    "  )\n",
    "  start_time = time.time()\n",
    "  # Forecast with covariates\n",
    "  # Output: new forecast, forecast by the xreg\n",
    "  cov_forecast, ols_forecast = model.forecast_with_covariates(  \n",
    "      inputs=example[\"inputs\"],\n",
    "      dynamic_numerical_covariates={\n",
    "          'last_7_days': example['last_7_days'],\n",
    "          'last_7_days_neighbor': example['last_7_days_neighbor'],\n",
    "      },\n",
    "      dynamic_categorical_covariates={\n",
    "          \n",
    "      },\n",
    "      static_numerical_covariates={\n",
    "        'long': example['long'],\n",
    "        'lat': example['lat']\n",
    "      },\n",
    "      static_categorical_covariates={\n",
    "        \"disease\": example['disease'],\n",
    "        \"county\": example[\"county\"]\n",
    "      },\n",
    "      freq=[0] * len(example[\"inputs\"]),\n",
    "      xreg_mode=\"xreg + timesfm\",              # default\n",
    "      ridge=0.0,\n",
    "      force_on_cpu=False,\n",
    "      normalize_xreg_target_per_input=True,    # default\n",
    "  )\n",
    "  print(\n",
    "      f\"\\rFinished batch {i} linear in {time.time() - start_time} seconds\",\n",
    "      end=\"\",\n",
    "  )\n",
    "  y_pred_timesfm.extend(raw_forecast[:, :horizon_len])\n",
    "  y_pred_xreg_timesfm.extend(cov_forecast)\n",
    "  y_pred_xreg.extend(ols_forecast)\n",
    "  y_true.extend(example[\"outputs\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import math\n",
    "sns.set_theme(style=\"darkgrid\",\n",
    "              rc={'figure.figsize':(21.7,8.27)})\n",
    "\n",
    "\n",
    "# Load an example dataset with long-form data\n",
    "y_true = np.reshape(y_true, (1, -1)).ravel()\n",
    "y_pred_timesfm = np.reshape(y_pred_timesfm, (1, -1)).ravel()\n",
    "y_pred_xreg_timesfm = np.reshape(y_pred_xreg_timesfm, (1, -1)).ravel()\n",
    "y_pred_xreg = np.reshape(y_pred_xreg, (1, -1)).ravel()\n",
    "\n",
    "y_pred_timesfm = abs(y_pred_timesfm)\n",
    "y_pred_xreg_timesfm = abs(y_pred_xreg_timesfm)\n",
    "y_pred_xreg = abs(y_pred_xreg)\n",
    "\n",
    "n = y_true.shape[0]\n",
    "\n",
    "s_date = pd.to_datetime('2020-01-01')\n",
    "\n",
    "plot_data = {\n",
    "    'timepoint': np.concatenate([pd.date_range(start=s_date+pd.Timedelta(days=365),end=s_date+pd.Timedelta(days=365+n-1), freq='D').values]*4),\n",
    "    'incidence': np.concatenate([y_true, y_pred_timesfm, y_pred_xreg_timesfm, y_pred_xreg],axis=None),\n",
    "    'type': np.concatenate([['y_true']*n, ['y_pred_timesfm']*n, ['y_pred_xreg_timesfm']*n, ['y_pred_xreg']*n],axis=None),\n",
    "}\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "ax = sns.lineplot(x=\"timepoint\", y=\"incidence\",\n",
    "             hue=\"type\",\n",
    "             data=df_plot)\n",
    "ax.set_title('Incidence of shouzukou in Lichengqu')\n",
    "\n",
    "print('mae_y_pred_timesfm:',mae([y_true], [y_pred_timesfm]))\n",
    "print('mae_y_pred_xreg_timesfm:',mae([y_true], [y_pred_xreg_timesfm]))\n",
    "print('mae_y_pred_xreg:',mae([y_true], [y_pred_xreg]))\n",
    "\n",
    "print('mse_y_pred_timesfm:',mse([y_true], [y_pred_timesfm]))\n",
    "print('mse_y_pred_xreg_timesfm:',mse([y_true], [y_pred_xreg_timesfm]))\n",
    "print('mse_y_pred_xreg:',mse([y_true], [y_pred_xreg]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data['timepoint'] =  np.concatenate([pd.date_range(start=df['onset_date'].min()+pd.Timedelta(days=365),end=df['onset_date'].min()+pd.Timedelta(days=365+n-1), freq='D').values]*4)\n",
    "plot_data['timepoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('mae_y_pred_timesfm:',mae([y_true], [y_pred_timesfm]))\n",
    "print('mae_y_pred_xreg_timesfm:',mae([y_true], [y_pred_xreg_timesfm]))\n",
    "print('mae_y_pred_xreg:',mae([y_true], [y_pred_xreg]))\n",
    "\n",
    "print('mse_y_pred_timesfm:',mse([y_true], [y_pred_timesfm]))\n",
    "print('mse_y_pred_xreg_timesfm:',mse([y_true], [y_pred_xreg_timesfm]))\n",
    "print('mse_y_pred_xreg:',mse([y_true], [y_pred_xreg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day[df_day['disease']=='手足口']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timesfm[torch]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
